<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>biobench.interfaces API documentation</title>
<meta name="description" content="Common interfaces for models and tasks so that it&#39;s easy to add new models (which will work right away with all tasks) and easy to add new tasks …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>biobench.interfaces</code></h1>
</header>
<section id="section-intro">
<p>Common interfaces for models and tasks so that it's easy to add new models (which will work right away with all tasks) and easy to add new tasks (which will work right away with all models).</p>
<p>The model interface is <code><a title="biobench.interfaces.VisionBackbone" href="#biobench.interfaces.VisionBackbone">VisionBackbone</a></code>.
See <code><a title="biobench.third_party_models" href="third_party_models.html">biobench.third_party_models</a></code> for examples of how to subclass it, and note that you have to call <code><a title="biobench.register_vision_backbone" href="index.html#biobench.register_vision_backbone">register_vision_backbone()</a></code> for it to show up.</p>
<p>The benchmark interface is informal, but is a function that matches the following signature:</p>
<pre><code class="language-py">def benchmark(args: Args, model_args: tuple[str, str]) -&gt; tuple[tuple[str, str], interfaces.TaskReport]:
    ...
</code></pre>
<p>In a Haskell-like signature, this is more like <code>Args -&gt; (str, str) -&gt; ((str, str), TaskReport)</code>.</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="biobench.interfaces.default_calc_mean_score"><code class="name flex">
<span>def <span class="ident">default_calc_mean_score</span></span>(<span>examples: list[<a title="biobench.interfaces.Example" href="#biobench.interfaces.Example">Example</a>]) ‑> float</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="biobench.interfaces.get_git_hash"><code class="name flex">
<span>def <span class="ident">get_git_hash</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the hash of the current git commit, assuming we are in a git repo.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="biobench.interfaces.EncodedImgBatch"><code class="flex name class">
<span>class <span class="ident">EncodedImgBatch</span></span>
<span>(</span><span>img_features: jaxtyping.Float[Tensor, 'batch img_dim'], patch_features: jaxtyping.Float[Tensor, 'batch n_patches patch_dim'] | None)</span>
</code></dt>
<dd>
<div class="desc"><p>The output of a <code><a title="biobench.interfaces.VisionBackbone" href="#biobench.interfaces.VisionBackbone">VisionBackbone</a></code>'s <code><a title="biobench.interfaces.VisionBackbone.img_encode" href="#biobench.interfaces.VisionBackbone.img_encode">VisionBackbone.img_encode()</a></code> method.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
@dataclasses.dataclass(frozen=True)
class EncodedImgBatch:
    &#34;&#34;&#34;The output of a `VisionBackbone`&#39;s `VisionBackbone.img_encode()` method.&#34;&#34;&#34;

    img_features: Float[Tensor, &#34;batch img_dim&#34;]
    &#34;&#34;&#34;Image-level features. Each image is represented by a single vector.&#34;&#34;&#34;
    patch_features: Float[Tensor, &#34;batch n_patches patch_dim&#34;] | None
    &#34;&#34;&#34;Patch-level features. Only ViTs have patch-level features. These features might be a different dimension that the image features because of projection heads or such.&#34;&#34;&#34;</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="biobench.interfaces.EncodedImgBatch.img_features"><code class="name">var <span class="ident">img_features</span> : jaxtyping.Float[Tensor, 'batch img_dim']</code></dt>
<dd>
<div class="desc"><p>Image-level features. Each image is represented by a single vector.</p></div>
</dd>
<dt id="biobench.interfaces.EncodedImgBatch.patch_features"><code class="name">var <span class="ident">patch_features</span> : jaxtyping.Float[Tensor, 'batch n_patches patch_dim'] | None</code></dt>
<dd>
<div class="desc"><p>Patch-level features. Only ViTs have patch-level features. These features might be a different dimension that the image features because of projection heads or such.</p></div>
</dd>
</dl>
</dd>
<dt id="biobench.interfaces.Example"><code class="flex name class">
<span>class <span class="ident">Example</span></span>
<span>(</span><span>id: str, score: float, info: dict[str, object])</span>
</code></dt>
<dd>
<div class="desc"><p>An individual test example.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
@dataclasses.dataclass(frozen=True)
class Example:
    &#34;&#34;&#34;An individual test example.&#34;&#34;&#34;

    id: str
    &#34;&#34;&#34;Whatever kind of ID; used to find the original image/example.&#34;&#34;&#34;
    score: float
    &#34;&#34;&#34;Test score; typically 0 or 1 for classification tasks.&#34;&#34;&#34;
    info: dict[str, object]
    &#34;&#34;&#34;Any additional information included. This might be the original class, the true label, etc.&#34;&#34;&#34;</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="biobench.interfaces.Example.id"><code class="name">var <span class="ident">id</span> : str</code></dt>
<dd>
<div class="desc"><p>Whatever kind of ID; used to find the original image/example.</p></div>
</dd>
<dt id="biobench.interfaces.Example.info"><code class="name">var <span class="ident">info</span> : dict[str, object]</code></dt>
<dd>
<div class="desc"><p>Any additional information included. This might be the original class, the true label, etc.</p></div>
</dd>
<dt id="biobench.interfaces.Example.score"><code class="name">var <span class="ident">score</span> : float</code></dt>
<dd>
<div class="desc"><p>Test score; typically 0 or 1 for classification tasks.</p></div>
</dd>
</dl>
</dd>
<dt id="biobench.interfaces.TaskArgs"><code class="flex name class">
<span>class <span class="ident">TaskArgs</span></span>
<span>(</span><span>seed: int = 42, datadir: str = '', device: str = 'cuda', debug: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Common args for all tasks.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
@dataclasses.dataclass(frozen=True)
class TaskArgs:
    &#34;&#34;&#34;Common args for all tasks.&#34;&#34;&#34;

    seed: int = 42
    &#34;&#34;&#34;random seed.&#34;&#34;&#34;
    datadir: str = &#34;&#34;
    &#34;&#34;&#34;dataset directory; where you downloaded this task&#39;s data to.&#34;&#34;&#34;
    # Computed at runtime.
    device: str = &#34;cuda&#34;
    &#34;&#34;&#34;(computed at runtime) which kind of accelerator to use.&#34;&#34;&#34;
    debug: bool = False
    &#34;&#34;&#34;(computed at runtime) whether to run in debug mode.&#34;&#34;&#34;</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="biobench.ages.Args" href="ages/index.html#biobench.ages.Args">Args</a></li>
<li><a title="biobench.beluga.Args" href="beluga/index.html#biobench.beluga.Args">Args</a></li>
<li><a title="biobench.birds525.Args" href="birds525/index.html#biobench.birds525.Args">Args</a></li>
<li><a title="biobench.fishnet.Args" href="fishnet/index.html#biobench.fishnet.Args">Args</a></li>
<li><a title="biobench.iwildcam.Args" href="iwildcam/index.html#biobench.iwildcam.Args">Args</a></li>
<li><a title="biobench.kabr.Args" href="kabr/index.html#biobench.kabr.Args">Args</a></li>
<li><a title="biobench.newt.Args" href="newt/index.html#biobench.newt.Args">Args</a></li>
<li><a title="biobench.plantnet.Args" href="plantnet/index.html#biobench.plantnet.Args">Args</a></li>
<li><a title="biobench.rarespecies.Args" href="rarespecies/index.html#biobench.rarespecies.Args">Args</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="biobench.interfaces.TaskArgs.datadir"><code class="name">var <span class="ident">datadir</span> : str</code></dt>
<dd>
<div class="desc"><p>dataset directory; where you downloaded this task's data to.</p></div>
</dd>
<dt id="biobench.interfaces.TaskArgs.debug"><code class="name">var <span class="ident">debug</span> : bool</code></dt>
<dd>
<div class="desc"><p>(computed at runtime) whether to run in debug mode.</p></div>
</dd>
<dt id="biobench.interfaces.TaskArgs.device"><code class="name">var <span class="ident">device</span> : str</code></dt>
<dd>
<div class="desc"><p>(computed at runtime) which kind of accelerator to use.</p></div>
</dd>
<dt id="biobench.interfaces.TaskArgs.seed"><code class="name">var <span class="ident">seed</span> : int</code></dt>
<dd>
<div class="desc"><p>random seed.</p></div>
</dd>
</dl>
</dd>
<dt id="biobench.interfaces.TaskReport"><code class="flex name class">
<span>class <span class="ident">TaskReport</span></span>
<span>(</span><span>name: str, examples: list[<a title="biobench.interfaces.Example" href="#biobench.interfaces.Example">Example</a>], *, calc_mean_score: Callable[[list[<a title="biobench.interfaces.Example" href="#biobench.interfaces.Example">Example</a>]], float] = &lt;function default_calc_mean_score&gt;, splits: dict[str, float] = &lt;factory&gt;, argv: list[str] = &lt;factory&gt;, commit: str = '8947c9013d2e5bab3619339ed77da5c61c0870f2', posix_time: float = &lt;factory&gt;, gpu_name: str = &lt;factory&gt;, hostname: str = &lt;factory&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>The result of running a benchmark task.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
@dataclasses.dataclass(frozen=True)
class TaskReport:
    &#34;&#34;&#34;
    The result of running a benchmark task.
    &#34;&#34;&#34;

    # Actual details of the report
    name: str
    &#34;&#34;&#34;The benchmark name.&#34;&#34;&#34;
    examples: list[Example]
    &#34;&#34;&#34;A list of (example_id, score, info) objects&#34;&#34;&#34;
    _: dataclasses.KW_ONLY
    calc_mean_score: typing.Callable[[list[Example]], float] = default_calc_mean_score
    &#34;&#34;&#34;A way to calculate mean score from a list of examples.&#34;&#34;&#34;
    splits: dict[str, float] = dataclasses.field(default_factory=dict)
    &#34;&#34;&#34;Other scores that you would like to report. These do not have confidence intervals.&#34;&#34;&#34;

    # Stuff for trying to reproduce this result. These are filled in by default.
    argv: list[str] = dataclasses.field(default_factory=lambda: sys.argv)
    &#34;&#34;&#34;Command used to get this report.&#34;&#34;&#34;
    commit: str = get_git_hash()
    &#34;&#34;&#34;Git commit for this current report.&#34;&#34;&#34;
    posix_time: float = dataclasses.field(default_factory=time.time)
    &#34;&#34;&#34;Time when this report was constructed.&#34;&#34;&#34;
    gpu_name: str = dataclasses.field(
        default_factory=lambda: torch.cuda.get_device_properties(0).name
    )
    &#34;&#34;&#34;Name of the GPU that ran this experiment.&#34;&#34;&#34;
    hostname: str = dataclasses.field(default_factory=socket.gethostname)
    &#34;&#34;&#34;Machine hostname that ran this experiment.&#34;&#34;&#34;

    def __repr__(self):
        return f&#34;Report({self.name} with {len(self.examples)} examples)&#34;

    def __str__(self):
        return repr(self)

    def get_mean_score(self) -&gt; float:
        &#34;&#34;&#34;
        Get the mean score of all examples.
        &#34;&#34;&#34;
        return self.calc_mean_score(self.examples)

    def get_confidence_interval(
        self,
        statistic=&#34;mean&#34;,
        confidence: float = 95,
        n_resamples: int = 500,
        seed: int = 42,
    ) -&gt; tuple[float, float]:
        &#34;&#34;&#34;
        Get the confidence interval for the statistics (mean) by bootstrapping individual scores of the examples.

        NOTE: it&#39;s crazy how much easier this would be in Jax. PyTrees of Examples would simply contains batch dimensions, and then I would `jax.vmap(get_mean_score)(batched_examples)`.
        &#34;&#34;&#34;

        rng = np.random.default_rng(seed=seed)
        choices = rng.choice(
            len(self.examples), size=(n_resamples, len(self.examples)), replace=True
        )

        scores = []
        for choice in choices:
            scores.append(self.calc_mean_score([self.examples[i] for i in choice]))

        percentiles = (100 - confidence) / 2, (100 - confidence) / 2 + confidence
        lower, upper = np.percentile(scores, percentiles).tolist()

        return lower, upper

    def to_dict(self) -&gt; dict[str, object]:
        &#34;&#34;&#34;
        Returns a json-encodable dictionary representation of self.
        &#34;&#34;&#34;
        return {
            &#34;name&#34;: self.name,
            &#34;examples&#34;: [dataclasses.asdict(example) for example in self.examples],
            &#34;argv&#34;: self.argv,
            &#34;commit&#34;: self.commit,
            &#34;posix_time&#34;: self.posix_time,
            &#34;gpu_name&#34;: self.gpu_name,
            &#34;hostname&#34;: self.hostname,
        }</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="biobench.interfaces.TaskReport.argv"><code class="name">var <span class="ident">argv</span> : list[str]</code></dt>
<dd>
<div class="desc"><p>Command used to get this report.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.commit"><code class="name">var <span class="ident">commit</span> : str</code></dt>
<dd>
<div class="desc"><p>Git commit for this current report.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.examples"><code class="name">var <span class="ident">examples</span> : list[<a title="biobench.interfaces.Example" href="#biobench.interfaces.Example">Example</a>]</code></dt>
<dd>
<div class="desc"><p>A list of (example_id, score, info) objects</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.gpu_name"><code class="name">var <span class="ident">gpu_name</span> : str</code></dt>
<dd>
<div class="desc"><p>Name of the GPU that ran this experiment.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.hostname"><code class="name">var <span class="ident">hostname</span> : str</code></dt>
<dd>
<div class="desc"><p>Machine hostname that ran this experiment.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"><p>The benchmark name.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.posix_time"><code class="name">var <span class="ident">posix_time</span> : float</code></dt>
<dd>
<div class="desc"><p>Time when this report was constructed.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.splits"><code class="name">var <span class="ident">splits</span> : dict[str, float]</code></dt>
<dd>
<div class="desc"><p>Other scores that you would like to report. These do not have confidence intervals.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="biobench.interfaces.TaskReport.calc_mean_score"><code class="name flex">
<span>def <span class="ident">calc_mean_score</span></span>(<span>examples: list[<a title="biobench.interfaces.Example" href="#biobench.interfaces.Example">Example</a>]) ‑> float</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="biobench.interfaces.TaskReport.get_confidence_interval"><code class="name flex">
<span>def <span class="ident">get_confidence_interval</span></span>(<span>self, statistic='mean', confidence: float = 95, n_resamples: int = 500, seed: int = 42) ‑> tuple[float, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the confidence interval for the statistics (mean) by bootstrapping individual scores of the examples.</p>
<p>NOTE: it's crazy how much easier this would be in Jax. PyTrees of Examples would simply contains batch dimensions, and then I would <code>jax.vmap(get_mean_score)(batched_examples)</code>.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.get_mean_score"><code class="name flex">
<span>def <span class="ident">get_mean_score</span></span>(<span>self) ‑> float</span>
</code></dt>
<dd>
<div class="desc"><p>Get the mean score of all examples.</p></div>
</dd>
<dt id="biobench.interfaces.TaskReport.to_dict"><code class="name flex">
<span>def <span class="ident">to_dict</span></span>(<span>self) ‑> dict[str, object]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a json-encodable dictionary representation of self.</p></div>
</dd>
</dl>
</dd>
<dt id="biobench.interfaces.VisionBackbone"><code class="flex name class">
<span>class <span class="ident">VisionBackbone</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A frozen vision model that embeds batches of images into batches of vectors.</p>
<p>To add new models to the benchmark, you can simply create a new class that satisfies this interface and register it.
See <code><a title="biobench.registry" href="registry.html">biobench.registry</a></code> for a tutorial on adding new vision backbones.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class VisionBackbone(torch.nn.Module):
    &#34;&#34;&#34;
    A frozen vision model that embeds batches of images into batches of vectors.

    To add new models to the benchmark, you can simply create a new class that satisfies this interface and register it.
    See `biobench.registry` for a tutorial on adding new vision backbones.
    &#34;&#34;&#34;

    def img_encode(
        self, batch: Float[Tensor, &#34;batch 3 width height&#34;]
    ) -&gt; EncodedImgBatch:
        &#34;&#34;&#34;Encode a batch of images.&#34;&#34;&#34;
        err_msg = f&#34;{self.__class__.__name__} must implemented img_encode().&#34;
        raise NotImplementedError(err_msg)

    def make_img_transform(self):
        &#34;&#34;&#34;
        Return whatever function the backbone wants for image preprocessing.
        This should be an evaluation transform, not a training transform, because we are using the output features of this backbone as data and not updating this backbone.
        &#34;&#34;&#34;
        err_msg = f&#34;{self.__class__.__name__} must implemented make_img_transform().&#34;
        raise NotImplementedError(err_msg)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="biobench.third_party_models.OpenClip" href="third_party_models.html#biobench.third_party_models.OpenClip">OpenClip</a></li>
<li><a title="biobench.third_party_models.TimmVit" href="third_party_models.html#biobench.third_party_models.TimmVit">TimmVit</a></li>
<li><a title="biobench.third_party_models.TorchvisionModel" href="third_party_models.html#biobench.third_party_models.TorchvisionModel">TorchvisionModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="biobench.interfaces.VisionBackbone.img_encode"><code class="name flex">
<span>def <span class="ident">img_encode</span></span>(<span>self, batch: jaxtyping.Float[Tensor, 'batch 3 width height']) ‑> <a title="biobench.interfaces.EncodedImgBatch" href="#biobench.interfaces.EncodedImgBatch">EncodedImgBatch</a></span>
</code></dt>
<dd>
<div class="desc"><p>Encode a batch of images.</p></div>
</dd>
<dt id="biobench.interfaces.VisionBackbone.make_img_transform"><code class="name flex">
<span>def <span class="ident">make_img_transform</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return whatever function the backbone wants for image preprocessing.
This should be an evaluation transform, not a training transform, because we are using the output features of this backbone as data and not updating this backbone.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="biobench" href="index.html">biobench</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="biobench.interfaces.default_calc_mean_score" href="#biobench.interfaces.default_calc_mean_score">default_calc_mean_score</a></code></li>
<li><code><a title="biobench.interfaces.get_git_hash" href="#biobench.interfaces.get_git_hash">get_git_hash</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="biobench.interfaces.EncodedImgBatch" href="#biobench.interfaces.EncodedImgBatch">EncodedImgBatch</a></code></h4>
<ul class="">
<li><code><a title="biobench.interfaces.EncodedImgBatch.img_features" href="#biobench.interfaces.EncodedImgBatch.img_features">img_features</a></code></li>
<li><code><a title="biobench.interfaces.EncodedImgBatch.patch_features" href="#biobench.interfaces.EncodedImgBatch.patch_features">patch_features</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="biobench.interfaces.Example" href="#biobench.interfaces.Example">Example</a></code></h4>
<ul class="">
<li><code><a title="biobench.interfaces.Example.id" href="#biobench.interfaces.Example.id">id</a></code></li>
<li><code><a title="biobench.interfaces.Example.info" href="#biobench.interfaces.Example.info">info</a></code></li>
<li><code><a title="biobench.interfaces.Example.score" href="#biobench.interfaces.Example.score">score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="biobench.interfaces.TaskArgs" href="#biobench.interfaces.TaskArgs">TaskArgs</a></code></h4>
<ul class="">
<li><code><a title="biobench.interfaces.TaskArgs.datadir" href="#biobench.interfaces.TaskArgs.datadir">datadir</a></code></li>
<li><code><a title="biobench.interfaces.TaskArgs.debug" href="#biobench.interfaces.TaskArgs.debug">debug</a></code></li>
<li><code><a title="biobench.interfaces.TaskArgs.device" href="#biobench.interfaces.TaskArgs.device">device</a></code></li>
<li><code><a title="biobench.interfaces.TaskArgs.seed" href="#biobench.interfaces.TaskArgs.seed">seed</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="biobench.interfaces.TaskReport" href="#biobench.interfaces.TaskReport">TaskReport</a></code></h4>
<ul class="">
<li><code><a title="biobench.interfaces.TaskReport.argv" href="#biobench.interfaces.TaskReport.argv">argv</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.calc_mean_score" href="#biobench.interfaces.TaskReport.calc_mean_score">calc_mean_score</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.commit" href="#biobench.interfaces.TaskReport.commit">commit</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.examples" href="#biobench.interfaces.TaskReport.examples">examples</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.get_confidence_interval" href="#biobench.interfaces.TaskReport.get_confidence_interval">get_confidence_interval</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.get_mean_score" href="#biobench.interfaces.TaskReport.get_mean_score">get_mean_score</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.gpu_name" href="#biobench.interfaces.TaskReport.gpu_name">gpu_name</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.hostname" href="#biobench.interfaces.TaskReport.hostname">hostname</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.name" href="#biobench.interfaces.TaskReport.name">name</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.posix_time" href="#biobench.interfaces.TaskReport.posix_time">posix_time</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.splits" href="#biobench.interfaces.TaskReport.splits">splits</a></code></li>
<li><code><a title="biobench.interfaces.TaskReport.to_dict" href="#biobench.interfaces.TaskReport.to_dict">to_dict</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="biobench.interfaces.VisionBackbone" href="#biobench.interfaces.VisionBackbone">VisionBackbone</a></code></h4>
<ul class="">
<li><code><a title="biobench.interfaces.VisionBackbone.img_encode" href="#biobench.interfaces.VisionBackbone.img_encode">img_encode</a></code></li>
<li><code><a title="biobench.interfaces.VisionBackbone.make_img_transform" href="#biobench.interfaces.VisionBackbone.make_img_transform">make_img_transform</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>

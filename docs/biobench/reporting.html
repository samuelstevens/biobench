<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>biobench.reporting API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>biobench.reporting</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="biobench.reporting.already_ran"><code class="name flex">
<span>def <span class="ident">already_ran</span></span>(<span>db: sqlite3.Connection,<br>cfg: <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a>,<br>task_name: str) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def already_ran(db: sqlite3.Connection, cfg: config.Experiment, task_name: str) -&gt; bool:
    &#34;&#34;&#34;Check if an experiment has already been run.

    Args:
        db: SQLite database connection
        cfg: Experiment configuration
        task_name: Name of the task to check

    Returns:
        bool: True if the experiment has already been run, False otherwise
    &#34;&#34;&#34;
    query = &#34;&#34;&#34;
    SELECT COUNT(*)
    FROM experiments
    WHERE task_name = ?
    AND model_org = ?
    AND model_ckpt = ?
    AND n_train = ?
    &#34;&#34;&#34;
    values = (task_name, cfg.model.org, cfg.model.ckpt, cfg.n_train)

    (count,) = db.execute(query, values).fetchone()
    return count &gt; 0</code></pre>
</details>
<div class="desc"><p>Check if an experiment has already been run.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db</code></strong></dt>
<dd>SQLite database connection</dd>
<dt><strong><code>cfg</code></strong></dt>
<dd>Experiment configuration</dd>
<dt><strong><code>task_name</code></strong></dt>
<dd>Name of the task to check</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if the experiment has already been run, False otherwise</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.bootstrap_scores_macro_f1"><code class="name flex">
<span>def <span class="ident">bootstrap_scores_macro_f1</span></span>(<span>df: polars.dataframe.frame.DataFrame,<br>*,<br>b: int = 0,<br>rng: numpy.random._generator.Generator | None = None) ‑> dict[str, jaxtyping.Float[ndarray, 'b']]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
def bootstrap_scores_macro_f1(
    df: pl.DataFrame, *, b: int = 0, rng: np.random.Generator | None = None
) -&gt; dict[str, Float[np.ndarray, &#34; b&#34;]]:
    &#34;&#34;&#34;
    Polars dataframe with schema

    Schema({&#39;task_name&#39;: String, &#39;model_ckpt&#39;: String, &#39;img_id&#39;: String, &#39;score&#39;: Float64, &#39;y_true&#39;: String, &#39;y_pred&#39;: String})
    &#34;&#34;&#34;

    n, *rest = df.group_by(&#34;model_ckpt&#34;).agg(n=pl.len()).get_column(&#34;n&#34;).to_list()
    assert all(n == i for i in rest)

    if b &gt; 0:
        assert rng is not None, &#34;must provide rng argument&#34;
        i_bs = rng.integers(0, n, size=(b, n), dtype=np.int32)

    scores = {}

    y_pred_buf = np.empty((b, n), dtype=np.int32)
    y_true_buf = np.empty((b, n), dtype=np.int32)

    for model_ckpt in df.get_column(&#34;model_ckpt&#34;).unique().sort().to_list():
        # pull y_true and y_pred for *one* model
        y_pred = (
            df.filter(pl.col(&#34;model_ckpt&#34;) == model_ckpt)
            .select(&#34;img_id&#34;, &#34;y_pred&#34;)
            .unique()
            .sort(&#34;img_id&#34;)
            .get_column(&#34;y_pred&#34;)
            .cast(pl.Float32)
            .cast(pl.Int32)
            .to_numpy()
        )

        if len(y_pred) == 0:
            continue

        y_true = (
            df.filter(pl.col(&#34;model_ckpt&#34;) == model_ckpt)
            .select(&#34;img_id&#34;, &#34;y_true&#34;)
            .unique()
            .sort(&#34;img_id&#34;)
            .get_column(&#34;y_true&#34;)
            .cast(pl.Float32)
            .cast(pl.Int32)
            .to_numpy()
        )
        assert y_true.size == y_pred.size

        if b &gt; 0:
            # bootstrap resample into pre-allocated buffers
            np.take(y_pred, i_bs, axis=0, out=y_pred_buf)
            np.take(y_true, i_bs, axis=0, out=y_true_buf)
            scores[model_ckpt] = macro_f1_batch(y_true_buf, y_pred_buf)
        else:
            scores[model_ckpt] = np.array([macro_f1_batch(y_true, y_pred)])

    return scores</code></pre>
</details>
<div class="desc"><p>Polars dataframe with schema</p>
<p>Schema({'task_name': String, 'model_ckpt': String, 'img_id': String, 'score': Float64, 'y_true': String, 'y_pred': String})</p></div>
</dd>
<dt id="biobench.reporting.claim_run"><code class="name flex">
<span>def <span class="ident">claim_run</span></span>(<span>db: sqlite3.Connection,<br>cfg: <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a>,<br>task_name: str) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def claim_run(db: sqlite3.Connection, cfg: config.Experiment, task_name: str) -&gt; bool:
    &#34;&#34;&#34;Try to claim (task_name, model, n_train).

    Args:
        db: SQLite database connection
        cfg: Experiment configuration
        task_name: Name of the task to claim

    Returns:
        bool: True if this process inserted the row and now &#34;owns&#34; the run,
              False if row already existed and another worker has it
    &#34;&#34;&#34;

    stmt = &#34;&#34;&#34;
    INSERT OR IGNORE INTO runs
    (task_name, model_org, model_ckpt, n_train, pid, posix)
    VALUES (?,?,?,?,?,?)
    &#34;&#34;&#34;
    values = (
        task_name,
        cfg.model.org,
        cfg.model.ckpt,
        cfg.n_train,
        os.getpid(),
        time.time(),
    )

    try:
        cur = db.execute(stmt, values)
        db.commit()
        return cur.rowcount == 1  # 1 row inserted -&gt; we won
    except Exception:
        db.rollback()
        raise</code></pre>
</details>
<div class="desc"><p>Try to claim (task_name, model, n_train).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db</code></strong></dt>
<dd>SQLite database connection</dd>
<dt><strong><code>cfg</code></strong></dt>
<dd>Experiment configuration</dd>
<dt><strong><code>task_name</code></strong></dt>
<dd>Name of the task to claim</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if this process inserted the row and now "owns" the run,
False if row already existed and another worker has it</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.clear_stale_claims"><code class="name flex">
<span>def <span class="ident">clear_stale_claims</span></span>(<span>db: sqlite3.Connection, *, max_age_hours: int = 72) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def clear_stale_claims(db: sqlite3.Connection, *, max_age_hours: int = 72) -&gt; int:
    &#34;&#34;&#34;
    Delete rows in `runs` whose POSIX timestamp is older than `max_age_hours`.

    Returns
    -------
    int
        Number of rows deleted.
    &#34;&#34;&#34;
    if max_age_hours &lt;= 0:
        raise ValueError(&#34;max_age_hours must be positive&#34;)

    cutoff = time.time() - max_age_hours * 3600
    try:
        cur = db.execute(&#34;DELETE FROM runs WHERE posix &lt; ?&#34;, (cutoff,))
        db.commit()
        return cur.rowcount
    except Exception:
        db.rollback()
        raise</code></pre>
</details>
<div class="desc"><p>Delete rows in <code>runs</code> whose POSIX timestamp is older than <code>max_age_hours</code>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of rows deleted.</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.get_db"><code class="name flex">
<span>def <span class="ident">get_db</span></span>(<span>cfg: <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a>) ‑> sqlite3.Connection</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def get_db(cfg: config.Experiment) -&gt; sqlite3.Connection:
    &#34;&#34;&#34;Get a connection to the reports database.

    Args:
        cfg: Experiment configuration

    Returns:
        sqlite3.Connection: A connection to the SQLite database
    &#34;&#34;&#34;
    os.makedirs(os.path.expandvars(cfg.report_to), exist_ok=True)
    helpers.warn_if_nfs(cfg.report_to)
    db_fpath = os.path.join(os.path.expandvars(cfg.report_to), &#34;reports.sqlite&#34;)
    db = sqlite3.connect(db_fpath, autocommit=True)

    with open(schema_fpath) as fd:
        schema = fd.read()
    db.executescript(schema)
    db.autocommit = False

    return db</code></pre>
</details>
<div class="desc"><p>Get a connection to the reports database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong></dt>
<dd>Experiment configuration</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>sqlite3.Connection</code></dt>
<dd>A connection to the SQLite database</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.get_git_hash"><code class="name flex">
<span>def <span class="ident">get_git_hash</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def get_git_hash() -&gt; str:
    &#34;&#34;&#34;Returns the hash of the current git commit.

    Returns:
        str: The hash of the current git commit, assuming we are in a git repo
    &#34;&#34;&#34;
    return subprocess.check_output([&#34;git&#34;, &#34;rev-parse&#34;, &#34;HEAD&#34;]).decode(&#34;ascii&#34;).strip()</code></pre>
</details>
<div class="desc"><p>Returns the hash of the current git commit.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The hash of the current git commit, assuming we are in a git repo</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.get_gpu_name"><code class="name flex">
<span>def <span class="ident">get_gpu_name</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_gpu_name() -&gt; str:
    import torch

    if torch.cuda.is_available():
        return torch.cuda.get_device_properties(0).name
    else:
        return &#34;&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="biobench.reporting.is_claimed"><code class="name flex">
<span>def <span class="ident">is_claimed</span></span>(<span>db: sqlite3.Connection,<br>cfg: <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a>,<br>task_name: str) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def is_claimed(db: sqlite3.Connection, cfg: config.Experiment, task_name: str) -&gt; bool:
    &#34;&#34;&#34;Check if a run is already claimed by another process.

    Args:
        db: SQLite database connection
        cfg: Experiment configuration
        task_name: Name of the task to check

    Returns:
        bool: True if the run is already claimed, False otherwise
    &#34;&#34;&#34;
    query = &#34;&#34;&#34;
    SELECT COUNT(*)
    FROM runs
    WHERE task_name = ?
    AND model_org = ?
    AND model_ckpt = ?
    AND n_train = ?
    &#34;&#34;&#34;
    values = (task_name, cfg.model.org, cfg.model.ckpt, cfg.n_train)

    (count,) = db.execute(query, values).fetchone()
    return count &gt; 0</code></pre>
</details>
<div class="desc"><p>Check if a run is already claimed by another process.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db</code></strong></dt>
<dd>SQLite database connection</dd>
<dt><strong><code>cfg</code></strong></dt>
<dd>Experiment configuration</dd>
<dt><strong><code>task_name</code></strong></dt>
<dd>Name of the task to check</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if the run is already claimed, False otherwise</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.macro_acc"><code class="name flex">
<span>def <span class="ident">macro_acc</span></span>(<span>preds: list[<a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a>]) ‑> float</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def macro_acc(preds: list[Prediction]) -&gt; float:
    y_pred = np.array([
        next(p.info[key] for key in (&#34;y_pred&#34;, &#34;pred_y&#34;) if key in p.info)
        for p in preds
    ])
    y_true = np.array([p.info.get(&#34;y_true&#34;, p.info.get(&#34;true_y&#34;)) for p in preds])
    return sklearn.metrics.balanced_accuracy_score(y_true, y_pred)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="biobench.reporting.macro_f1"><code class="name flex">
<span>def <span class="ident">macro_f1</span></span>(<span>preds: list[<a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a>],<br>*,<br>labels: list[int] | None = None) ‑> float</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def macro_f1(preds: list[Prediction], *, labels: list[int] | None = None) -&gt; float:
    y_pred = np.array([
        next(p.info[key] for key in (&#34;y_pred&#34;, &#34;pred_y&#34;) if key in p.info)
        for p in preds
    ])
    y_true = np.array([p.info.get(&#34;y_true&#34;, p.info.get(&#34;true_y&#34;)) for p in preds])

    if labels is None:
        labels = np.unique(np.stack([y_true, y_pred]))
        labels = np.arange(labels.max() + 1)
    else:
        labels = np.array(labels)

    assert (np.arange(labels.size) == labels).all()

    return sklearn.metrics.f1_score(
        y_true, y_pred, average=&#34;macro&#34;, labels=labels, zero_division=0.0
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="biobench.reporting.macro_f1_batch"><code class="name flex">
<span>def <span class="ident">macro_f1_batch</span></span>(<span>y_true: jaxtyping.Int[ndarray, '*batch n'],<br>y_pred: jaxtyping.Int[ndarray, '*batch n'],<br>*,<br>labels: jaxtyping.Int[ndarray, 'c'] | None = None) ‑> jaxtyping.Float[ndarray, '*batch']</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
def macro_f1_batch(
    y_true: Int[np.ndarray, &#34;*batch n&#34;],
    y_pred: Int[np.ndarray, &#34;*batch n&#34;],
    *,
    labels: Int[np.ndarray, &#34; c&#34;] | None = None,
) -&gt; Float[np.ndarray, &#34;*batch&#34;]:
    &#34;&#34;&#34;
    Vectorised macro-F1 for large class counts.

    Accepts any leading `*batch` prefix; the last axis `n` is the number
    of examples.  Runs in O(B·n) time and O(B·C) memory, where
    B = prod(*batch) and C = #classes.

    All elements in y_true, y_pred, and labels must be integers ≥ 0. (Negative IDs would break the offset arithmetic; floats break np.bincount.)
    &#34;&#34;&#34;

    # flatten batch prefix
    *batch_shape, n = y_true.shape
    b = int(np.prod(batch_shape))  # total batches

    y_true = y_true.reshape(b, n)
    y_pred = y_pred.reshape(b, n)

    # label remapping to dense 0...C-1
    if labels is None:
        labels = np.unique(np.stack([y_true, y_pred]))

    labels = np.arange(labels.max() + 1)
    c = labels.size
    assert (np.arange(c) == labels).all()

    # offsets for per-batch bincounts
    offset = np.arange(b, dtype=np.int64)[:, None] * c  # (b, 1)
    yz_true = y_true + offset  # (b, n)
    yz_pred = y_pred + offset  # (b, n)

    # counts for all examples
    true_cnt = np.bincount(yz_true.ravel(), minlength=(b * c)).reshape(b, c)
    pred_cnt = np.bincount(yz_pred.ravel(), minlength=(b * c)).reshape(b, c)

    # true-positives
    tp_mask = y_true == y_pred  # (B, n)
    tp_off = yz_true[tp_mask]  # 1-D
    tp_cnt = np.bincount(tp_off, minlength=(b * c)).reshape(b, c)

    # F1 per class, then macro average
    fp = pred_cnt - tp_cnt
    fn = true_cnt - tp_cnt
    denom = 2 * tp_cnt + fp + fn  # (B, C)

    f1_c = np.zeros_like(denom, dtype=float)
    np.divide(2 * tp_cnt, denom, out=f1_c, where=denom != 0)

    macro_f1 = f1_c.mean(axis=-1)  # (B,)
    return macro_f1.reshape(batch_shape)</code></pre>
</details>
<div class="desc"><p>Vectorised macro-F1 for large class counts.</p>
<p>Accepts any leading <code>*batch</code> prefix; the last axis <code>n</code> is the number
of examples.
Runs in O(B·n) time and O(B·C) memory, where
B = prod(*batch) and C = #classes.</p>
<p>All elements in y_true, y_pred, and labels must be integers ≥ 0. (Negative IDs would break the offset arithmetic; floats break np.bincount.)</p></div>
</dd>
<dt id="biobench.reporting.micro_acc"><code class="name flex">
<span>def <span class="ident">micro_acc</span></span>(<span>preds: list[<a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a>]) ‑> float</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def micro_acc(preds: list[Prediction]) -&gt; float:
    y_pred = np.array([
        next(p.info[key] for key in (&#34;y_pred&#34;, &#34;pred_y&#34;) if key in p.info)
        for p in preds
    ])
    y_true = np.array([p.info.get(&#34;y_true&#34;, p.info.get(&#34;true_y&#34;)) for p in preds])
    return sklearn.metrics.accuracy_score(y_true, y_pred)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="biobench.reporting.micro_acc_batch"><code class="name flex">
<span>def <span class="ident">micro_acc_batch</span></span>(<span>y_true: jaxtyping.Int[ndarray, '*batch n'],<br>y_pred: jaxtyping.Int[ndarray, '*batch n']) ‑> jaxtyping.Float[ndarray, '*batch']</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def micro_acc_batch(
    y_true: Int[np.ndarray, &#34;*batch n&#34;], y_pred: Int[np.ndarray, &#34;*batch n&#34;]
) -&gt; Float[np.ndarray, &#34;*batch&#34;]:
    &#34;&#34;&#34;
    Vectorised **micro-accuracy** (overall proportion of correct predictions).

    * Works on any leading `*batch` prefix; the final axis `n` is the number of examples.
    * Complexity O(B·n) time, O(1) extra memory.

    Parameters
    ----------
    y_true, y_pred
        Integer class labels / predictions ≥ 0.  All leading dimensions
        (`*batch`) must match; `n` is the sample count.

    Returns
    -------
    acc : np.ndarray
        Shape `*batch`; accuracy for every element of the batch prefix.
    &#34;&#34;&#34;
    acc = (y_true == y_pred).mean(axis=-1, dtype=float)
    return acc</code></pre>
</details>
<div class="desc"><p>Vectorised <strong>micro-accuracy</strong> (overall proportion of correct predictions).</p>
<ul>
<li>Works on any leading <code>*batch</code> prefix; the final axis <code>n</code> is the number of examples.</li>
<li>Complexity O(B·n) time, O(1) extra memory.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y_true</code></strong>, <strong><code>y_pred</code></strong></dt>
<dd>Integer class labels / predictions ≥ 0.
All leading dimensions
(<code>*batch</code>) must match; <code>n</code> is the sample count.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>acc</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Shape <code>*batch</code>; accuracy for every element of the batch prefix.</dd>
</dl></div>
</dd>
<dt id="biobench.reporting.micro_f1"><code class="name flex">
<span>def <span class="ident">micro_f1</span></span>(<span>preds: list[<a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a>]) ‑> float</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def micro_f1(preds: list[Prediction]) -&gt; float:
    y_pred = np.array([
        next(p.info[key] for key in (&#34;y_pred&#34;, &#34;pred_y&#34;) if key in p.info)
        for p in preds
    ])
    y_true = np.array([p.info.get(&#34;y_true&#34;, p.info.get(&#34;true_y&#34;)) for p in preds])
    return sklearn.metrics.f1_score(y_true, y_pred, average=&#34;micro&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="biobench.reporting.release_run"><code class="name flex">
<span>def <span class="ident">release_run</span></span>(<span>db: sqlite3.Connection,<br>cfg: <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a>,<br>task_name: str) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def release_run(db: sqlite3.Connection, cfg: config.Experiment, task_name: str) -&gt; None:
    &#34;&#34;&#34;Delete the coordination row so others may claim again.

    Args:
        db: SQLite database connection
        cfg: Experiment configuration
        task_name: Name of the task to release
    &#34;&#34;&#34;
    stmt = &#34;&#34;&#34;
    DELETE FROM runs
    WHERE task_name=? AND model_org=? AND model_ckpt=? AND n_train=?
    &#34;&#34;&#34;
    values = (task_name, cfg.model.org, cfg.model.ckpt, cfg.n_train)
    logger.info(&#34;Releasing claim on (%s, %s, %s, %d)&#34;, *values)

    try:
        db.execute(stmt, values)
        db.commit()
        logger.info(&#34;Released claim on (%s, %s, %s, %d)&#34;, *values)
    except Exception:
        db.rollback()
        raise</code></pre>
</details>
<div class="desc"><p>Delete the coordination row so others may claim again.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>db</code></strong></dt>
<dd>SQLite database connection</dd>
<dt><strong><code>cfg</code></strong></dt>
<dd>Experiment configuration</dd>
<dt><strong><code>task_name</code></strong></dt>
<dd>Name of the task to release</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="biobench.reporting.Prediction"><code class="flex name class">
<span>class <span class="ident">Prediction</span></span>
<span>(</span><span>id: str, score: float, info: dict[str, object])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Prediction:
    &#34;&#34;&#34;An individual test prediction.&#34;&#34;&#34;

    id: str
    &#34;&#34;&#34;Whatever kind of ID; used to find the original image/example.&#34;&#34;&#34;
    score: float
    &#34;&#34;&#34;Test score; typically 0 or 1 for classification tasks.&#34;&#34;&#34;
    info: dict[str, object]
    &#34;&#34;&#34;Any additional information included. This might be the original class, the true label, etc.&#34;&#34;&#34;</code></pre>
</details>
<div class="desc"><p>An individual test prediction.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="biobench.reporting.Prediction.id"><code class="name">var <span class="ident">id</span> : str</code></dt>
<dd>
<div class="desc"><p>Whatever kind of ID; used to find the original image/example.</p></div>
</dd>
<dt id="biobench.reporting.Prediction.info"><code class="name">var <span class="ident">info</span> : dict[str, object]</code></dt>
<dd>
<div class="desc"><p>Any additional information included. This might be the original class, the true label, etc.</p></div>
</dd>
<dt id="biobench.reporting.Prediction.score"><code class="name">var <span class="ident">score</span> : float</code></dt>
<dd>
<div class="desc"><p>Test score; typically 0 or 1 for classification tasks.</p></div>
</dd>
</dl>
</dd>
<dt id="biobench.reporting.Report"><code class="flex name class">
<span>class <span class="ident">Report</span></span>
<span>(</span><span>task_name: str,<br>predictions: list[<a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a>],<br>cfg: <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a>,<br>*,<br>splits: dict[str, float] = &lt;factory&gt;,<br>argv: list[str] = &lt;factory&gt;,<br>git_commit: str = '2a48b81a123cbf4fef3150f441acbea8c02143a0',<br>posix: float = &lt;factory&gt;,<br>gpu_name: str = &lt;factory&gt;,<br>hostname: str = &lt;factory&gt;)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
@dataclasses.dataclass(frozen=True)
class Report:
    &#34;&#34;&#34;
    The result of running a benchmark task.
    &#34;&#34;&#34;

    # Actual details of the report
    task_name: str
    &#34;&#34;&#34;The benchmark name.&#34;&#34;&#34;
    predictions: list[Prediction]
    &#34;&#34;&#34;A list of (example_id, score, info) objects&#34;&#34;&#34;
    cfg: config.Experiment
    &#34;&#34;&#34;Experimental config.&#34;&#34;&#34;
    _: dataclasses.KW_ONLY
    splits: dict[str, float] = dataclasses.field(default_factory=dict)
    &#34;&#34;&#34;Other scores that you would like to report. These do not have confidence intervals.&#34;&#34;&#34;

    # Stuff for trying to reproduce this result. These are filled in by default.
    argv: list[str] = dataclasses.field(default_factory=lambda: sys.argv)
    &#34;&#34;&#34;Command used to get this report.&#34;&#34;&#34;
    git_commit: str = get_git_hash()
    &#34;&#34;&#34;Git commit for this current report.&#34;&#34;&#34;
    posix: float = dataclasses.field(default_factory=time.time)
    &#34;&#34;&#34;Time when this report was constructed.&#34;&#34;&#34;
    gpu_name: str = dataclasses.field(default_factory=get_gpu_name)
    &#34;&#34;&#34;Name of the GPU that ran this experiment.&#34;&#34;&#34;
    hostname: str = dataclasses.field(default_factory=socket.gethostname)
    &#34;&#34;&#34;Machine hostname that ran this experiment.&#34;&#34;&#34;

    def __repr__(self):
        return f&#34;Report({self.task_name} with {len(self.predictions)} predictions)&#34;

    def __str__(self):
        return repr(self)

    @beartype.beartype
    def write(self) -&gt; None:
        &#34;&#34;&#34;Saves the report to disk in a machine-readable SQLite format.&#34;&#34;&#34;
        db = get_db(self.cfg)

        preds_stmt = &#34;INSERT INTO predictions(img_id, score, info, experiment_id) VALUES(?, ?, ?, ?)&#34;
        exp_stmt = &#34;INSERT INTO experiments(task_name, model_org, model_ckpt, n_train, exp_cfg, argv, git_commit, posix, gpu_name, hostname) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&#34;
        try:
            cursor = db.cursor()

            exp_values = (
                self.task_name.lower(),
                self.cfg.model.org,
                self.cfg.model.ckpt,
                self.cfg.n_train,
                json.dumps(self.cfg.to_dict()),
                json.dumps(self.argv),
                self.git_commit,
                self.posix,
                self.gpu_name,
                self.hostname,
            )
            cursor.execute(exp_stmt, exp_values)
            exp_id = cursor.lastrowid
            preds_values = [
                (pred.id, pred.score, json.dumps(pred.info), exp_id)
                for pred in self.predictions
            ]
            cursor.executemany(preds_stmt, preds_values)

            # Commit the transaction if all statements succeed
            db.commit()
        except sqlite3.Error as err:
            # Roll back the transaction in case of error
            db.rollback()
            logger.critical(&#34;Error writing report for &#39;%s&#39;: %s&#34;, self.task_name, err)
            raise</code></pre>
</details>
<div class="desc"><p>The result of running a benchmark task.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="biobench.reporting.Report.argv"><code class="name">var <span class="ident">argv</span> : list[str]</code></dt>
<dd>
<div class="desc"><p>Command used to get this report.</p></div>
</dd>
<dt id="biobench.reporting.Report.cfg"><code class="name">var <span class="ident">cfg</span> : <a title="biobench.config.Experiment" href="config.html#biobench.config.Experiment">Experiment</a></code></dt>
<dd>
<div class="desc"><p>Experimental config.</p></div>
</dd>
<dt id="biobench.reporting.Report.git_commit"><code class="name">var <span class="ident">git_commit</span> : str</code></dt>
<dd>
<div class="desc"><p>Git commit for this current report.</p></div>
</dd>
<dt id="biobench.reporting.Report.gpu_name"><code class="name">var <span class="ident">gpu_name</span> : str</code></dt>
<dd>
<div class="desc"><p>Name of the GPU that ran this experiment.</p></div>
</dd>
<dt id="biobench.reporting.Report.hostname"><code class="name">var <span class="ident">hostname</span> : str</code></dt>
<dd>
<div class="desc"><p>Machine hostname that ran this experiment.</p></div>
</dd>
<dt id="biobench.reporting.Report.posix"><code class="name">var <span class="ident">posix</span> : float</code></dt>
<dd>
<div class="desc"><p>Time when this report was constructed.</p></div>
</dd>
<dt id="biobench.reporting.Report.predictions"><code class="name">var <span class="ident">predictions</span> : list[<a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a>]</code></dt>
<dd>
<div class="desc"><p>A list of (example_id, score, info) objects</p></div>
</dd>
<dt id="biobench.reporting.Report.splits"><code class="name">var <span class="ident">splits</span> : dict[str, float]</code></dt>
<dd>
<div class="desc"><p>Other scores that you would like to report. These do not have confidence intervals.</p></div>
</dd>
<dt id="biobench.reporting.Report.task_name"><code class="name">var <span class="ident">task_name</span> : str</code></dt>
<dd>
<div class="desc"><p>The benchmark name.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="biobench.reporting.Report.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
def write(self) -&gt; None:
    &#34;&#34;&#34;Saves the report to disk in a machine-readable SQLite format.&#34;&#34;&#34;
    db = get_db(self.cfg)

    preds_stmt = &#34;INSERT INTO predictions(img_id, score, info, experiment_id) VALUES(?, ?, ?, ?)&#34;
    exp_stmt = &#34;INSERT INTO experiments(task_name, model_org, model_ckpt, n_train, exp_cfg, argv, git_commit, posix, gpu_name, hostname) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&#34;
    try:
        cursor = db.cursor()

        exp_values = (
            self.task_name.lower(),
            self.cfg.model.org,
            self.cfg.model.ckpt,
            self.cfg.n_train,
            json.dumps(self.cfg.to_dict()),
            json.dumps(self.argv),
            self.git_commit,
            self.posix,
            self.gpu_name,
            self.hostname,
        )
        cursor.execute(exp_stmt, exp_values)
        exp_id = cursor.lastrowid
        preds_values = [
            (pred.id, pred.score, json.dumps(pred.info), exp_id)
            for pred in self.predictions
        ]
        cursor.executemany(preds_stmt, preds_values)

        # Commit the transaction if all statements succeed
        db.commit()
    except sqlite3.Error as err:
        # Roll back the transaction in case of error
        db.rollback()
        logger.critical(&#34;Error writing report for &#39;%s&#39;: %s&#34;, self.task_name, err)
        raise</code></pre>
</details>
<div class="desc"><p>Saves the report to disk in a machine-readable SQLite format.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="biobench" href="index.html">biobench</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="biobench.reporting.already_ran" href="#biobench.reporting.already_ran">already_ran</a></code></li>
<li><code><a title="biobench.reporting.bootstrap_scores_macro_f1" href="#biobench.reporting.bootstrap_scores_macro_f1">bootstrap_scores_macro_f1</a></code></li>
<li><code><a title="biobench.reporting.claim_run" href="#biobench.reporting.claim_run">claim_run</a></code></li>
<li><code><a title="biobench.reporting.clear_stale_claims" href="#biobench.reporting.clear_stale_claims">clear_stale_claims</a></code></li>
<li><code><a title="biobench.reporting.get_db" href="#biobench.reporting.get_db">get_db</a></code></li>
<li><code><a title="biobench.reporting.get_git_hash" href="#biobench.reporting.get_git_hash">get_git_hash</a></code></li>
<li><code><a title="biobench.reporting.get_gpu_name" href="#biobench.reporting.get_gpu_name">get_gpu_name</a></code></li>
<li><code><a title="biobench.reporting.is_claimed" href="#biobench.reporting.is_claimed">is_claimed</a></code></li>
<li><code><a title="biobench.reporting.macro_acc" href="#biobench.reporting.macro_acc">macro_acc</a></code></li>
<li><code><a title="biobench.reporting.macro_f1" href="#biobench.reporting.macro_f1">macro_f1</a></code></li>
<li><code><a title="biobench.reporting.macro_f1_batch" href="#biobench.reporting.macro_f1_batch">macro_f1_batch</a></code></li>
<li><code><a title="biobench.reporting.micro_acc" href="#biobench.reporting.micro_acc">micro_acc</a></code></li>
<li><code><a title="biobench.reporting.micro_acc_batch" href="#biobench.reporting.micro_acc_batch">micro_acc_batch</a></code></li>
<li><code><a title="biobench.reporting.micro_f1" href="#biobench.reporting.micro_f1">micro_f1</a></code></li>
<li><code><a title="biobench.reporting.release_run" href="#biobench.reporting.release_run">release_run</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="biobench.reporting.Prediction" href="#biobench.reporting.Prediction">Prediction</a></code></h4>
<ul class="">
<li><code><a title="biobench.reporting.Prediction.id" href="#biobench.reporting.Prediction.id">id</a></code></li>
<li><code><a title="biobench.reporting.Prediction.info" href="#biobench.reporting.Prediction.info">info</a></code></li>
<li><code><a title="biobench.reporting.Prediction.score" href="#biobench.reporting.Prediction.score">score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="biobench.reporting.Report" href="#biobench.reporting.Report">Report</a></code></h4>
<ul class="two-column">
<li><code><a title="biobench.reporting.Report.argv" href="#biobench.reporting.Report.argv">argv</a></code></li>
<li><code><a title="biobench.reporting.Report.cfg" href="#biobench.reporting.Report.cfg">cfg</a></code></li>
<li><code><a title="biobench.reporting.Report.git_commit" href="#biobench.reporting.Report.git_commit">git_commit</a></code></li>
<li><code><a title="biobench.reporting.Report.gpu_name" href="#biobench.reporting.Report.gpu_name">gpu_name</a></code></li>
<li><code><a title="biobench.reporting.Report.hostname" href="#biobench.reporting.Report.hostname">hostname</a></code></li>
<li><code><a title="biobench.reporting.Report.posix" href="#biobench.reporting.Report.posix">posix</a></code></li>
<li><code><a title="biobench.reporting.Report.predictions" href="#biobench.reporting.Report.predictions">predictions</a></code></li>
<li><code><a title="biobench.reporting.Report.splits" href="#biobench.reporting.Report.splits">splits</a></code></li>
<li><code><a title="biobench.reporting.Report.task_name" href="#biobench.reporting.Report.task_name">task_name</a></code></li>
<li><code><a title="biobench.reporting.Report.write" href="#biobench.reporting.Report.write">write</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>

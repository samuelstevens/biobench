<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.5">
<title>biobench.birds525 API documentation</title>
<meta name="description" content="Species classification of 525 different bird species; this dataset is from [Kaggle](https://www.kaggle.com/datasets/gpiosenka/100-bird-species) …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>biobench.birds525</code></h1>
</header>
<section id="section-intro">
<p>Species classification of 525 different bird species; this dataset is from <a href="https://www.kaggle.com/datasets/gpiosenka/100-bird-species">Kaggle</a> (although it was down when I wrote this docstring, several weeks after downloading the data).</p>
<p>We use simpleshot and mimic the setting in <a href="https://imageomics.github.io/bioclip/">BioCLIP</a>: we randomly select 1 example from each class, then evaluate on the validation set.</p>
<p>We are interested in understanding the variance associated with using different training examples.
However, the <code><a title="biobench.interfaces.TaskReport.get_confidence_interval" href="../interfaces.html#biobench.interfaces.TaskReport.get_confidence_interval">TaskReport.get_confidence_interval()</a></code> method only passes a list of scored test examples, not a set of new training examples.
To get around this, the <code><a title="benchmark" href="../../benchmark.html">benchmark</a></code> function re-samples training data and re-runs the simpleshot algorithm 100 times.
Then when the <code><a title="biobench.interfaces.TaskReport.get_confidence_interval" href="../interfaces.html#biobench.interfaces.TaskReport.get_confidence_interval">TaskReport.get_confidence_interval()</a></code> is called, we randomly return one of the scores.
This gives a pretty tight confidence interval because <code><a title="biobench.interfaces.TaskReport.get_confidence_interval" href="../interfaces.html#biobench.interfaces.TaskReport.get_confidence_interval">TaskReport.get_confidence_interval()</a></code> will do 500 resamples by default, but at least we re-run training with different training examples.</p>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="biobench.birds525.download" href="download.html">biobench.birds525.download</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="biobench.birds525.benchmark_cvml"><code class="name flex">
<span>def <span class="ident">benchmark_cvml</span></span>(<span>args: <a title="biobench.birds525.Args" href="#biobench.birds525.Args">Args</a>,<br>model_args: <a title="biobench.interfaces.ModelArgsCvml" href="../interfaces.html#biobench.interfaces.ModelArgsCvml">ModelArgsCvml</a>) ‑> tuple[<a title="biobench.interfaces.ModelArgsCvml" href="../interfaces.html#biobench.interfaces.ModelArgsCvml">ModelArgsCvml</a>, <a title="biobench.interfaces.TaskReport" href="../interfaces.html#biobench.interfaces.TaskReport">TaskReport</a>]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def benchmark_cvml(
    args: Args, model_args: interfaces.ModelArgsCvml
) -&gt; tuple[interfaces.ModelArgsCvml, interfaces.TaskReport]:
    &#34;&#34;&#34;
    Runs simpleshot `Args.n_repeats` times (default 100) with 1 training example per class, then evaluates on the validation split.
    &#34;&#34;&#34;

    backbone = registry.load_vision_backbone(*model_args)
    train_features = get_features(args, backbone, is_train=True)
    test_features = get_features(args, backbone, is_train=False)

    all_scores = []
    for r in range(args.n_repeats):
        i = choose_k_per_class(train_features.y, k=1)

        scores = simpleshot.simpleshot(
            train_features.x[i],
            train_features.y[i],
            test_features.x,
            test_features.y,
            args.batch_size,
            args.device,
        )
        all_scores.append(torch.mean(scores).cpu())
        if (r + 1) % args.log_every == 0:
            logger.info(
                &#34;%d/%d simpleshot finished (%.1f%%)&#34;,
                r + 1,
                args.n_repeats,
                (r + 1) / args.n_repeats * 100,
            )

    all_scores = np.array(all_scores)

    # Just choose the last sampled result&#39;s examples.
    examples = [
        interfaces.Prediction(str(id), float(score), {})
        for id, score in zip(test_features.ids, scores.tolist())
    ]

    # We sort of cheat here. We run simpleshot n_repeats (100) times, then when we want to calculate the confidence intervals, we just choose the score of one of these simpleshot runs, regardless of what examples are passed.
    return model_args, interfaces.TaskReport(
        &#34;Birds525-1shot&#34;,
        examples,
        calc_mean_score=ChooseRandomCachedResult(args.seed, all_scores),
    )</code></pre>
</details>
<div class="desc"><p>Runs simpleshot <code><a title="biobench.birds525.Args.n_repeats" href="#biobench.birds525.Args.n_repeats">Args.n_repeats</a></code> times (default 100) with 1 training example per class, then evaluates on the validation split.</p></div>
</dd>
<dt id="biobench.birds525.choose_k_per_class"><code class="name flex">
<span>def <span class="ident">choose_k_per_class</span></span>(<span>labels: jaxtyping.Int[Tensor, 'n'], *, k: int) ‑> jaxtyping.Int[Tensor, 'n_train']</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def choose_k_per_class(labels: Int[Tensor, &#34; n&#34;], *, k: int) -&gt; Int[Tensor, &#34; n_train&#34;]:
    &#34;&#34;&#34;
    Returns indices for a label set that include at most `k` examples per class.

    Args:
        labels: a list of integer labels for a set of data.
        k: the maximum number of examples per class.

    Returns:
        indices for `labels` such that at most `k` examples per class are in the data.
    &#34;&#34;&#34;
    classes = np.unique(labels)

    train_indices = np.array([], dtype=int)

    # Iterate through each class to select indices
    for cls in classes:
        # Indices corresponding to the current class
        cls_indices = np.where(labels == cls)[0]
        # Randomly shuffle the indices
        np.random.shuffle(cls_indices)
        # Select the first K indices for the train set
        cls_train_indices = cls_indices[:k]
        # Append the selected indices to the train array
        train_indices = np.concatenate((train_indices, cls_train_indices))

    # Shuffle the indices to mix classes
    np.random.shuffle(train_indices)

    return torch.from_numpy(train_indices)</code></pre>
</details>
<div class="desc"><p>Returns indices for a label set that include at most <code>k</code> examples per class.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>labels</code></strong></dt>
<dd>a list of integer labels for a set of data.</dd>
<dt><strong><code>k</code></strong></dt>
<dd>the maximum number of examples per class.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>indices for <code>labels</code> such that at most <code>k</code> examples per class are in the data.</p></div>
</dd>
<dt id="biobench.birds525.get_features"><code class="name flex">
<span>def <span class="ident">get_features</span></span>(<span>args: <a title="biobench.birds525.Args" href="#biobench.birds525.Args">Args</a>,<br>backbone: <a title="biobench.interfaces.VisionBackbone" href="../interfaces.html#biobench.interfaces.VisionBackbone">VisionBackbone</a>,<br>*,<br>is_train: bool) ‑> <a title="biobench.birds525.Features" href="#biobench.birds525.Features">Features</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_features(
    args: Args, backbone: interfaces.VisionBackbone, *, is_train: bool
) -&gt; Features:
    &#34;&#34;&#34;
    Get a block of features from a vision backbone for a split (either train or test).

    Args:
        args: Birds525 arguments.
        backbone: visual backbone.
        is_train: whether you want training data or the test data.
    &#34;&#34;&#34;
    img_transform = backbone.make_img_transform()
    backbone = torch.compile(backbone.to(args.device))

    split = &#34;train&#34; if is_train else &#34;valid&#34;

    root = os.path.join(args.datadir, split)
    if not os.path.isdir(root):
        msg = f&#34;Path &#39;{root}&#39; doesn&#39;t exist. Did you download the Birds525 dataset? See the docstring at the top of this file for instructions. If you did download it, pass the path with &#39;--datadir&#39;; see --help for more.&#34;
        raise ValueError(msg)
    dataset = Dataset(os.path.join(args.datadir, split), img_transform)

    dataloader = torch.utils.data.DataLoader(
        dataset=dataset,
        batch_size=args.batch_size,
        num_workers=args.n_workers,
        drop_last=False,
        shuffle=True,
    )

    all_features, all_labels, all_ids = [], [], []

    total = len(dataloader) if not args.debug else 2
    it = iter(dataloader)
    logger.debug(&#34;Need to embed %d batches of %d images.&#34;, total, args.batch_size)
    for b in helpers.progress(range(total), every=args.log_every, desc=split):
        ids, images, labels = next(it)
        images = images.to(args.device)

        with torch.amp.autocast(&#34;cuda&#34;):
            features = backbone.img_encode(images).img_features

        all_features.append(features.cpu())
        all_labels.extend(labels)
        all_ids.extend(ids)

    all_features = torch.cat(all_features, dim=0).cpu()
    all_ids = np.array(all_ids)
    all_labels = torch.tensor(all_labels)
    logger.info(&#34;Got features for %d images.&#34;, len(all_ids))

    return Features(all_features, all_labels, all_ids)</code></pre>
</details>
<div class="desc"><p>Get a block of features from a vision backbone for a split (either train or test).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>args</code></strong></dt>
<dd>Birds525 arguments.</dd>
<dt><strong><code>backbone</code></strong></dt>
<dd>visual backbone.</dd>
<dt><strong><code>is_train</code></strong></dt>
<dd>whether you want training data or the test data.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="biobench.birds525.Args"><code class="flex name class">
<span>class <span class="ident">Args</span></span>
<span>(</span><span>seed: int = 42,<br>data: str = '',<br>batch_size: int = 256,<br>n_workers: int = 4,<br>log_every: int = 10,<br>n_repeats: int = 100,<br>max_examples: int = -1,<br>device: str = 'cuda',<br>debug: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype.beartype
@dataclasses.dataclass(frozen=True)
class Args:
    &#34;&#34;&#34;
    Arguments for Birds525.
    &#34;&#34;&#34;

    seed: int = 42
    &#34;&#34;&#34;random seed.&#34;&#34;&#34;
    data: str = &#34;&#34;
    &#34;&#34;&#34;dataset directory; where you downloaded this task&#39;s data to.&#34;&#34;&#34;

    batch_size: int = 256
    &#34;&#34;&#34;batch size for deep model.&#34;&#34;&#34;
    n_workers: int = 4
    &#34;&#34;&#34;number of dataloader worker processes.&#34;&#34;&#34;
    log_every: int = 10
    &#34;&#34;&#34;how often (number of batches) to log progress.&#34;&#34;&#34;
    n_repeats: int = 100
    &#34;&#34;&#34;number of times to do 1-shot training.&#34;&#34;&#34;
    # Computed at runtime.
    max_examples: int = -1
    &#34;&#34;&#34;(computed at runtime) Number of maximum training samples. Negative number means use all of them.&#34;&#34;&#34;
    device: str = &#34;cuda&#34;
    &#34;&#34;&#34;(computed at runtime) Which kind of accelerator to use.&#34;&#34;&#34;
    debug: bool = False
    &#34;&#34;&#34;(computed at runtime) Whether to run in debug mode.&#34;&#34;&#34;</code></pre>
</details>
<div class="desc"><p>Arguments for Birds525.</p></div>
<h3>Class variables</h3>
<dl>
<dt id="biobench.birds525.Args.batch_size"><code class="name">var <span class="ident">batch_size</span> : int</code></dt>
<dd>
<div class="desc"><p>batch size for deep model.</p></div>
</dd>
<dt id="biobench.birds525.Args.data"><code class="name">var <span class="ident">data</span> : str</code></dt>
<dd>
<div class="desc"><p>dataset directory; where you downloaded this task's data to.</p></div>
</dd>
<dt id="biobench.birds525.Args.debug"><code class="name">var <span class="ident">debug</span> : bool</code></dt>
<dd>
<div class="desc"><p>(computed at runtime) Whether to run in debug mode.</p></div>
</dd>
<dt id="biobench.birds525.Args.device"><code class="name">var <span class="ident">device</span> : str</code></dt>
<dd>
<div class="desc"><p>(computed at runtime) Which kind of accelerator to use.</p></div>
</dd>
<dt id="biobench.birds525.Args.log_every"><code class="name">var <span class="ident">log_every</span> : int</code></dt>
<dd>
<div class="desc"><p>how often (number of batches) to log progress.</p></div>
</dd>
<dt id="biobench.birds525.Args.max_examples"><code class="name">var <span class="ident">max_examples</span> : int</code></dt>
<dd>
<div class="desc"><p>(computed at runtime) Number of maximum training samples. Negative number means use all of them.</p></div>
</dd>
<dt id="biobench.birds525.Args.n_repeats"><code class="name">var <span class="ident">n_repeats</span> : int</code></dt>
<dd>
<div class="desc"><p>number of times to do 1-shot training.</p></div>
</dd>
<dt id="biobench.birds525.Args.n_workers"><code class="name">var <span class="ident">n_workers</span> : int</code></dt>
<dd>
<div class="desc"><p>number of dataloader worker processes.</p></div>
</dd>
<dt id="biobench.birds525.Args.seed"><code class="name">var <span class="ident">seed</span> : int</code></dt>
<dd>
<div class="desc"><p>random seed.</p></div>
</dd>
</dl>
</dd>
<dt id="biobench.birds525.ChooseRandomCachedResult"><code class="flex name class">
<span>class <span class="ident">ChooseRandomCachedResult</span></span>
<span>(</span><span>seed, scores: jaxtyping.Float[ndarray, 'n'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class ChooseRandomCachedResult:
    &#34;&#34;&#34;
    We sort of cheat here. We run simpleshot `Args.n_repeats` (100) times, then when we want to calculate the confidence intervals, we just randomly choose the score of one of these simpleshot runs, regardless of what examples are passed.
    &#34;&#34;&#34;

    def __init__(self, seed, scores: Float[np.ndarray, &#34; n&#34;]):
        self._scores = scores
        self._rng = np.random.default_rng(seed=seed)

    def __call__(self, examples: list[interfaces.Prediction]) -&gt; float:
        return self._rng.choice(self._scores).item()</code></pre>
</details>
<div class="desc"><p>We sort of cheat here. We run simpleshot <code><a title="biobench.birds525.Args.n_repeats" href="#biobench.birds525.Args.n_repeats">Args.n_repeats</a></code> (100) times, then when we want to calculate the confidence intervals, we just randomly choose the score of one of these simpleshot runs, regardless of what examples are passed.</p></div>
</dd>
<dt id="biobench.birds525.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>root: str | pathlib.Path,<br>transform: Callable | None = None,<br>target_transform: Callable | None = None,<br>loader: Callable[[str], Any] = &lt;function default_loader&gt;,<br>is_valid_file: Callable[[str], bool] | None = None,<br>allow_empty: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
class Dataset(torchvision.datasets.ImageFolder):
    &#34;&#34;&#34;
    Subclasses ImageFolder so that `__getitem__` includes the path, which we use as the ID.
    &#34;&#34;&#34;

    def __getitem__(self, index: int) -&gt; tuple[str, object, object]:
        &#34;&#34;&#34;
        Args:
            index (int): Index

        Returns:
            tuple: (path, sample, target) where target is class_index of the target class.
        &#34;&#34;&#34;
        path, target = self.samples[index]
        sample = self.loader(path)
        if self.transform is not None:
            sample = self.transform(sample)
        if self.target_transform is not None:
            target = self.target_transform(target)

        return path, sample, target</code></pre>
</details>
<div class="desc"><p>Subclasses ImageFolder so that <code>__getitem__</code> includes the path, which we use as the ID.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torchvision.datasets.folder.ImageFolder</li>
<li>torchvision.datasets.folder.DatasetFolder</li>
<li>torchvision.datasets.vision.VisionDataset</li>
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
</dd>
<dt id="biobench.birds525.Features"><code class="flex name class">
<span>class <span class="ident">Features</span></span>
<span>(</span><span>x: jaxtyping.Float[Tensor, 'n dim'],<br>y: jaxtyping.Int[Tensor, 'n'],<br>ids: jaxtyping.Shaped[ndarray, 'n'])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jaxtyped(typechecker=beartype.beartype)
@dataclasses.dataclass(frozen=True)
class Features:
    &#34;&#34;&#34;
    A block of features.

    Note: In Jax, this could be a tuple of arrays, all with a leading dimension of `n`. Instead, in PyTorch, it&#39;s easier to make it its own class. Oh well.
    &#34;&#34;&#34;

    x: Float[Tensor, &#34; n dim&#34;]
    &#34;&#34;&#34;Input features; from a `biobench.interfaces.VisionBackbone`.&#34;&#34;&#34;
    y: Int[Tensor, &#34; n&#34;]
    &#34;&#34;&#34;Class label.&#34;&#34;&#34;
    ids: Shaped[np.ndarray, &#34; n&#34;]
    &#34;&#34;&#34;Array of ids; could be strings, could be ints, etc.&#34;&#34;&#34;</code></pre>
</details>
<div class="desc"><p>A block of features.</p>
<p>Note: In Jax, this could be a tuple of arrays, all with a leading dimension of <code>n</code>. Instead, in PyTorch, it's easier to make it its own class. Oh well.</p></div>
<h3>Class variables</h3>
<dl>
<dt id="biobench.birds525.Features.ids"><code class="name">var <span class="ident">ids</span> : jaxtyping.Shaped[ndarray, 'n']</code></dt>
<dd>
<div class="desc"><p>Array of ids; could be strings, could be ints, etc.</p></div>
</dd>
<dt id="biobench.birds525.Features.x"><code class="name">var <span class="ident">x</span> : jaxtyping.Float[Tensor, 'n dim']</code></dt>
<dd>
<div class="desc"><p>Input features; from a <code><a title="biobench.interfaces.VisionBackbone" href="../interfaces.html#biobench.interfaces.VisionBackbone">VisionBackbone</a></code>.</p></div>
</dd>
<dt id="biobench.birds525.Features.y"><code class="name">var <span class="ident">y</span> : jaxtyping.Int[Tensor, 'n']</code></dt>
<dd>
<div class="desc"><p>Class label.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="biobench" href="../index.html">biobench</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="biobench.birds525.download" href="download.html">biobench.birds525.download</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="biobench.birds525.benchmark_cvml" href="#biobench.birds525.benchmark_cvml">benchmark_cvml</a></code></li>
<li><code><a title="biobench.birds525.choose_k_per_class" href="#biobench.birds525.choose_k_per_class">choose_k_per_class</a></code></li>
<li><code><a title="biobench.birds525.get_features" href="#biobench.birds525.get_features">get_features</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="biobench.birds525.Args" href="#biobench.birds525.Args">Args</a></code></h4>
<ul class="two-column">
<li><code><a title="biobench.birds525.Args.batch_size" href="#biobench.birds525.Args.batch_size">batch_size</a></code></li>
<li><code><a title="biobench.birds525.Args.data" href="#biobench.birds525.Args.data">data</a></code></li>
<li><code><a title="biobench.birds525.Args.debug" href="#biobench.birds525.Args.debug">debug</a></code></li>
<li><code><a title="biobench.birds525.Args.device" href="#biobench.birds525.Args.device">device</a></code></li>
<li><code><a title="biobench.birds525.Args.log_every" href="#biobench.birds525.Args.log_every">log_every</a></code></li>
<li><code><a title="biobench.birds525.Args.max_examples" href="#biobench.birds525.Args.max_examples">max_examples</a></code></li>
<li><code><a title="biobench.birds525.Args.n_repeats" href="#biobench.birds525.Args.n_repeats">n_repeats</a></code></li>
<li><code><a title="biobench.birds525.Args.n_workers" href="#biobench.birds525.Args.n_workers">n_workers</a></code></li>
<li><code><a title="biobench.birds525.Args.seed" href="#biobench.birds525.Args.seed">seed</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="biobench.birds525.ChooseRandomCachedResult" href="#biobench.birds525.ChooseRandomCachedResult">ChooseRandomCachedResult</a></code></h4>
</li>
<li>
<h4><code><a title="biobench.birds525.Dataset" href="#biobench.birds525.Dataset">Dataset</a></code></h4>
</li>
<li>
<h4><code><a title="biobench.birds525.Features" href="#biobench.birds525.Features">Features</a></code></h4>
<ul class="">
<li><code><a title="biobench.birds525.Features.ids" href="#biobench.birds525.Features.ids">ids</a></code></li>
<li><code><a title="biobench.birds525.Features.x" href="#biobench.birds525.Features.x">x</a></code></li>
<li><code><a title="biobench.birds525.Features.y" href="#biobench.birds525.Features.y">y</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.5</a>.</p>
</footer>
</body>
</html>
